\newpage
\section{Support Vector Machine}
% short description of the algorithm
The Support Vector Machine (SVM) algorithm learn linear classifiers, finding a linear classifier that is the \textbf{maximum margin separator hyperplane} and so achive the maximum margin from all the point in the training set.\\

Given a linearly separable training set $S = \{(\boldsymbol{x}_1, y_1), \dots, (\boldsymbol{x}_n, y_n)\} \in \mathbb{R}^d \times \{-1, 1\}$ it's possible to find this hyperplane solving the following convex optimization problem with linear constraints.\\ 
\begin{align*} 
    & \underset{\boldsymbol{w} \in \mathbb{R}^d}{\min} \ \frac{1}{2} \Vert \boldsymbol{w} \Vert^2 \\
    & \text{s.t.} \ y_t \boldsymbol{w}^\top \boldsymbol{x}_t \geq 1 \ \text{for} \ t = 1, \dots, m 
\end{align*}

In case the training data is not separable, we try to minimise both how much of each constraint is violated and the margin of the separator.\\
We express this as another convex problem using the slack variables $\xi_t$ and a regularisation coefficient $\lambda$.
If the regularisation coefficient is large, the algorithms will generate a predictor that allows more classification error in the training set.\\
Conversely, if $\lambda$ is small, we try to minimise the classification error we have made.\\
Usually for $\lambda$ too small, we try to minimise the misclassification, so the training error is small and we are likely to overfit.\\
Instead, for choices of $\lambda$ too large, we have a high training error, and if the test error is also high, we will underfit. \\In the next subsection, I describe how I choose the hyperparameter of the regularisation coefficient and how the test and training errors vary when I change it more precisely.\\ % TODO: label reference

\begin{align*}
    \underset{(\boldsymbol{w}, \boldsymbol{\xi}) \in \mathbb{R}^{d+m}}{\min} \quad & \frac{\lambda}{2} \Vert \boldsymbol{w} \Vert^2 + \frac{1}{m} \sum_{t = 1}^m \xi_t \\
    \text{s.t.} \quad & y_t \boldsymbol{w}^\top \boldsymbol{x}_t \geq 1 - \xi_t & t = 1, \dots, m \\
    & \xi_t \geq 0 \ \text{for} & t = 1, \dots, m
\end{align*}

Now, fix $\boldsymbol{w} \in \mathbb{R}^d$, we can see $\xi_t = \left[1 - y_t \boldsymbol{w}^\top \boldsymbol{x}_t \right]_+$ which is the hinge loss  $h_{t}(\boldsymbol{w})$.\\

The SVM problem can be rewritten as $$\underset{\boldsymbol{w} \in \mathbb{R}^d}{\min} \ \frac{\lambda}{2} \Vert \boldsymbol{w} \Vert^2 + \frac{1}{m} \sum_{t = 1}^m h_{t}(\boldsymbol{w})$$.\\

% TODO: computational cost of the svm model
The optimization problem that describe the Support Vector Machine is optimized using the Pegasos algorithm.\\
The Pegasos algorithm is a variant of the Stocastic Gradient Descent algorithm, where at each step a point (or a set of points in the mini-batch variant) is sampled randomly from the training set
and the current predictor is updated with the negative gradient of the loss of that training example weighted by a learning rate factor $\eta_t$.\\
In case of Pegasos the learning rate factor $\eta_t$ is choose at each step as $\frac{1}{\lambda t}$.\\
I implement the Pegasos algorithm using the standard variant with the hinge loss, and with the logistic loss (Described in the Logistic regression parameter).\\
Both this functions are convex upper bounds of the zero-one loss, and the $\lambda$ regularization parameter allow to have a $\lambda$-strongly convex function to minimize with the gradient descent.\\
% TODO: because of this fact we use the bound from OGD and obtain the one over the expected value for Pegasos
\subsection{Naive}
As I previously said I implemented Pegasos using two surrogate losses: hinge loss and logistic loss.\\
Now I describe the implementation with hinge loss, that differs from the logistic one only by the update step.\\ 
Recall that the hinge loss is defined as $l(y, \hat{y}) = \max\{0, 1 - y_t \hat{y}\}$\\
Given $Z_t = (X_t, Y_t)$ a random sample from the training set, the update rule for Pegasos is:\\
$$\boldsymbol{w}_{t+1} = \boldsymbol{w}_t - \eta_t \nabla\ell_{Z_t}(w_t)$$

Let be $s_t$ the realization for the random variable $Z_t$\\ 
Where $\ell_{s_t}(w) = \left[1 - y_{s_t} \boldsymbol{w}^T x_{s_t}\right]_+ + \frac{\lambda}{2} ||w||^2$ so
$$\nabla\ell_{s_t}(w) = -y_{s_t} x_{s_t} \mathbb{I}\{h_{s_t}(\boldsymbol{w}) > 0\} + \lambda w $$
Let $\boldsymbol{v_t} = y_t x_t I\{h_t(\boldsymbol{w_t}) > 0\}$ and choosing $\eta_t = \frac{1}{\lambda t}$ we have
$$\boldsymbol{w}_{t+1} = \boldsymbol{w}_t (1 - \frac{1}{t}) + \frac{1}{\lambda t} \boldsymbol{v_t}$$

\subsubsection{implementation details}
I adapted this version of the algorithm from \textit{Pegasos: Primal Estimated sub-GrAdient SOlver for SVM}\cite{Pegasos_paper}\\

\begin{algorithm}[H]
    \SetAlgoLined
    \DontPrintSemicolon
    \caption{Pegasos Algorithm}
    \KwIn{$S$, $\lambda$, $T$}
    \For{$t = 1, 2, \dots, T$}{
        Choose $i_t$ uniformly at random.\\
        Set $\eta_t = \frac{1}{\lambda t}$\\
        \If{$y_{it} \boldsymbol{w}_t^T x_{i_{t}} < 1$}{
            Set $\boldsymbol{w}_{t+1} \leftarrow (1 - \eta_t \lambda)\boldsymbol{w}_t + \eta_t y_{it} \boldsymbol{x}_{i_{t}}$
            }
            \Else {
                Set $\boldsymbol{w}_{t+1} \leftarrow (1 - \eta_t \lambda)\boldsymbol{w}_t$
        }
    }    
    Output $\boldsymbol{w}_{T+1}$
\end{algorithm}

The name of the variables are adapted to be consistent with the pseudo code reported\\
Between the code presented in the lecture and this one presented in the paper there are some differences with the pseudocode presented during the lectures:\\
\begin{itemize}
    \item The gradient descent update is written in a slightly different way using a conditional statement instead of the classical indicator function, I choose to remain consistent also with this stilistic choice.\\
    \item Instead of return the average of all the weight vector calculated at each step, the paper returns only the last one.\\ 
    The authors indicates that they notate an improvment in performance returning the last vector instead of the average.\\ 
    I embrace also this variation.\\
    \item In the pseudo code of Pegasos they also describe an optional projection step to clamp the magnitude of the linear predictor, but I don't incorporate it.\\ 
    % TODO: mini-batch: if I test also the mini-batch I should report if I notice some improvment and how the algorithm change based on the hyperparameter
    \item The author also provide a mini-batch version of the Pegasos algorithm, using the batch size $k$ as another hyperparameter.\\
\end{itemize}

Another approach proposed by the paper is {\bf sampling without replacement}: so a random permutation of the training set is choosen and the updates are performed in order on the new sequence of data.
In this way, in one epoch, a training point is sampled only once.\\
After each epoch we can choose if we restart to sample data sequentially according to the same permutation or create a new one and sampling according that new order.\\
Although the authors report that this approaches gives better results than uniform sampling as I did, I haven't experiment this variant of the algorithm.\\

\subsubsection{Hyperparameter tuning}
Unlike the perceptron, the Pegasos algorithm had a hyperparameter to choose from: The regularisation coefficient $\lambda$.\\
To choose the best hyperparameter for this algorithm (and the others that I will implement), I choose the grid search method.\
I divide the training set into 2 different subsets: $S_{traing}$ and $S_{dev}$.\\
The validation set ($S_{dev}$) is used as a surrogate test set to get an estimate of the risk.\\
I choose a finite subset of the possible hyperparameter values ($\Theta_0 \subseteq \Theta$) and for each of them I create a predictor $h_\theta$ which is trained with the chosen hyperparameter on $S_{train}$.\\
The risk is then estimated using the validation error on each predictor, and the one with the lower risk is chosen.\\
The implementation of the grid search in my codebase is in the function 'grid\_search', I used python know arguments to pass a dictionary where the key is the name of the hyperparameter (the same as used as an argument in the training algorithm) and the value is an iterator containing the subset of possible values ($\Theta_0$).\\ 
In this case, I choose the set $\Theta_0 = \{ 0.0001, 0.001, 0.01, 0.1, 1, 10, 100 \}$.\\

\begin{center}
    \begin{tabular}{| c | c | c |}
        \hline
        $\lambda$ & $S_{val}$ & $S_{train}$ \\
        \hline
        0.0001 & 0.3725 & 0.3521666 \\
        \hline
        0.001 & 0.2925 & 0.281333 \\
        \hline
        0.01 & 0.273 & 0.27 \\
        \hline
        \textbf{0.1} & \textbf{0.267} & \textbf{0.2661666} \\
        \hline
        1 & 0.273 & 0.269333 \\
        \hline
        10 & 0.279 & 0.2775 \\
        \hline
        100 & 0.2805 & 0.276333 \\
        \hline
    \end{tabular}
    \\
    The values $S_{val}$ and $S_{train}$ while $\lambda$ changes.\\
\end{center}

% TODO: rivedere questa parte, devo eseguire i test error su tutti i predictor??
Looking at the table we can deduce for which choice of $\lambda$ we underfit and overfit and in our case the sweet spot is the value for $\lambda = 0.1$.\\
The test error for the best predictor is 0.2935.\\
We can also see that for smaller value of lambda we have an high test error and model is overfitting while for large value are likely to underfit.\\
The weight for the Pegasos algorithm are the following: \\
0.2080856  -0.0066276   0.07067274 -0.26477777  0.24795273 -0.06704699\\
0.28821758  0.65130349  0.16619769 -0.06650096 -0.0724

\subsection{Logistic regression}
Logistic regression aim to learn the function $\eta(\boldsymbol{x}) = \mathbb{P}(Y = +1\ |\ \textbf{X} = \boldsymbol{x})$.\\
The implementation of logistic regression differs from the standard Pegasos because it uses the logistic loss as surrogate loss and not hinge.\\
The logistic loss is defines ad follows: $$\ell(y, \hat{y}) = \log_2 (1+e^{-y\hat{y}}).$$\\
So the gradient descent update becomes: $$\boldsymbol{w}_{t+1} = \boldsymbol{w}_t + \eta_t \sigma(-y_t \boldsymbol{w}^T \boldsymbol{x}_t) y_t \boldsymbol{x}_t$$\\
I choose the regularization parameter in the same way and obtained the following result.\\
\begin{center}
    \begin{tabular}{| c | c | c |}
        \hline
        $\lambda$ & $S_{val}$ & $S_{train}$ \\
        \hline
        0.1 & 0.278 & 0.2718333 \\
        \hline
        \textbf{1} & \textbf{0.2735} & \textbf{0.274333} \\
        \hline
        10 & 0.28325 & 0.27816 \\
        \hline
        100 & 0.2805 & 0.278166 \\
        \hline
    \end{tabular}
    \\
    The values $S_{val}$ and $S_{train}$ while $\lambda$ changes for the logistic loss.\\
\end{center}

I have choosen the hyperparameter $\lambda = 1$ and obtained a test error of: 0.292.\\

\subsection{Feature Expansion}
I have also trained the two previous algorithm over the polynomial feature expansion of second degree of the whole dataset.\\
Like in the case of perceptron, since we are able to express a separator in an high dimension we obtain better results than the native version (at the cost of an increasing number of feature in the dataset).\\  
\subsubsection{Pegasos}
\subsubsection{Logistic Regression}
% Support Vector Machine (Pegasos)
%   - naive
%       - Hyperparameter tuning
%          grid search with his implementation
%       - implementation details
%           (compare the implementation with the one on the paper)
%           kernelized version typo: the index i_t in the summation
%       - results
%           - Overfitting and under fitting (theoric view)
%   - logistic regression
%       - results
%           - Overfitting and under fitting (theoric view)
%   - with Feature expansion
%   - logistic regression with Feature expansion